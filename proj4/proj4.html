<!DOCTYPE html>
<!-- saved from url=(0028)http://localhost:8000/upload -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>Project 4</title>
<style type="text/css">
body{
	/*width: 760px; /* how wide to make your web page */
	/*background-color: #dddddd;*/ /* what color to make the background */
	margin: 0 auto;
	/*padding: 50px;*/
	font:12px/16px Verdana, sans-serif; /* default font */
}
div#main{
	/*background-color: #dddddd;*/
	margin: 0;
	padding: 50px;
	/*padding: 10px;*/
}
h1 {
	text-decoration: underline;
	text-align:center;
}
h2 {
	text-align:center;
}
td {
	text-align:center;
	vertical-align:center;
}
.radiance {
	height:300px;
}
.graph {
	width:500px;
}
.large_graph {
	width:500px;
}
.photo {
	width:100px;
	display:none;
}
.equation {
	font-style:italic;
	font-family: serif;
	font-size: 200%;
	text-align:center;
}
.poster {
	text-align: center;
	max-height: 500px;
	max-width: 500px;
}
.radiance_div {
	text-align:center;
}
#title-div {
	height:20vh;
}
#poster-div {
	height: 50vh;
	text-align:center;
}
#FAKE {
	text-align:center;
	color: red;
	font-size: 500%;
}
#REAL {
	text-align:center;
	color: green;
	font-size: 500%;
}
#ERROR {
	text-align:center;
	font-size: 500%;
}
table, th, td {
	border: 1px solid black;
}
th, td {
	width: 100px;
	height: 50px;
}
</style>
<style type="text/css"></style></head>
<body>
	<div id="title-div">
	<h1> CSE 555 (Computational Photography) Project 4 </h1>
	<h1> Real/fake image classification with Machine Learning </h1>
	<h2> Mark Heimann &amp; Jing Dao Chen 05/06/2015 </h2>
	</div>

	<div id="FAKE"><b><i> FAKE (1.3527%)</i></b></div><br><br>
	<div id="poster-div">
		<img class="poster" src="./graphs/img"><br>
	</div>

	<div id="main">		
		<h3> Upload Photo </h3>
		<form id="uploadForm" action="./proj4_files/proj4.html" method="post" enctype="multipart/form-data">
			<input type="hidden" name="csrfmiddlewaretoken" value="cn4tUFay4tG50iAFusE1p9f7RjJX14mM">
		    <input type="file" name="myfile">
			<input type="submit" name="submit" value="Upload">
		</form>
		<p>




		</p>
		<h3>Introduction</h3>
		<p> Digital photography has made it easier than ever to capture realistic-looking portraits of the world, but so have advances in computer graphics.  Many profound developments have made their way into commercial image-editing software, so that it is now possible for almost anyone to make all manner of non-photorealistic images as well as extremely photorealistic images.  Separating natural, unaltered photographs of real-life scenes from altered or artifically constructed images can thus be a challenge.  It is very important to do so, however, as images become sensations on social media or are submitted into evidence in courts of law.  </p>
		<br>
		<p>
		We gathered data of real images and a variety of fake images, including clip art as well as more photorealistic renderings, to train a machine learning classifier to predict whether images were real or altered.  We continued in the machine learning vein of Lyu and Farid (2005), but we took advantage of recent developments in deep learning to learn a richer representation of the data as features for our classifier On a separate test dataset, we demonstrate that our model is able to distinguish between natural and altered images with an extremely high degree of accuracy.    
		</p>
		<p>
       	<h3>Data</h3>
		The image data was taken from several websites to cover a variety of image categories.
		Real images were taken from photographs of buildings, sceneries and objects while fake images were taken from clip art, 3D rendered models and photorealistic images.
		We gathered 6000 real and 6000 fake images in total which constitutes our final data set. However, we found that even with a smaller sample size of 2000 images in each category, we were able to generate comparable results to the full data set.
		The images below show examples of pictures from our data set.<br><br>
		<div class="radiance_div"><img class="radiance" src="graphs/real1.jpg">
		<img class="radiance" src="graphs/real2.jpg"><br><br>
		<b>Real data set</b><br><br> </div>
		<div class="radiance_div"><img class="radiance" src="graphs/easy1.png">
		<img class="radiance" src="graphs/easy2.png"><br><br>
		<b>Easy fake data set</b><br><br> </div>
		<div class="radiance_div"><img class="radiance" src="graphs/hard1.jpg">
		<img class="radiance" src="graphs/hard2.jpg"><br><br>
		<b>Hard fake data set</b><br><br> </div>

		Before using the images as input to the neural network, we preprocessed them by resizing to a standard dimension and subtracted the image mean.
		The images were labelled as either real or fake and collected in an array.
		They are then separated into 80% training data and 20% test data in randomized order.
		</p>
		<p>
		<h3>Methodology and Results</h3>

		Our method relies on the pre-trained <i>AlexNet</i> neural network, available through <i>Caffe</i> Deep Learning Framework.
		For each input image, a forward iteration is performed to output values at convolutional, pooling and fully connected layers.
		For example the graph below shows the mean value of each of the 4096 features at the 'fc7' layer for real vs fake images.<br><br>
		<div class="radiance_div">
			<img class="graph" src="graphs/mean_features.png"><br><br>
		</div>

		The features were taken from 4 different layers of the neural network, namely the inner fully connected layers fc6, fc7, fc8 and the top layer probability output, prob.
		The feature values were saved to file in matrices of N x D where N is the number of images and D is the number of features.
		The label for each image (0 for fake images and 1 for real images) was saved in a separate N x 1 array.<br><br>

		We then applied a Logistic Regression model to the data using the <i>scikit-learn</i> platform.
		The classifier was trained wth 80% of our data and the remaining 20% was used to test the classifier.
		The test error was measured in terms of differences between predicted labels and true labels.  

		The test results are tabulated below: (the test error range indicates difference between easy and hard data sets) <br><br>
		<table><tr> <th><b>Layer</b></th> <th>fc6</th> <th>fc7</th> <th>fc8</th> <th>prob</th> <th>fc7</th> <th>fc8</th></tr>
		<tr> <td><b>Number of features</b></td> <td>4096</td> <td>1000</td> <td>1000</td> <td>1000</td> <td>4096</td> <td>1000</td></tr>
		<tr> <td><b>Total images</b></td> <td>4000</td> <td>4000</td> <td>4000</td> <td>4000</td> <td>12000</td> <td>12000</td></tr>
		<tr> <td><b>Test error (%)</b></td> <td>0.5 - 3.6</td> <td>0.8 - 4.4</td> <td>1.1 - 5.5</td> <td>6.8 - 12.0</td> <td>2.3</td> <td>3.8</td></tr>
		</table>
		<br><br>
		Overall, the method showed quite excellent performance in terms of test error rate.
		We found that using the fully connected hidden layers achieves the best results, with an error rate as low as 0.5%.
		</p>
       
		<h3>Discussion</h3>
		Challenges:	
		<ul>
			<li>Setting up the neural network and its dependencies took a while.</li>
			<li>Long processing times.</li>
		</ul>
		Future Work:
		<ul>
			<li>Concatenate feature arrays from multiple layers.</li>
			<li>Collect more data.</li>
			<li>Experiment with different CNN architectures.</li>
		</ul>
		<p>
		<h3> Image Dataset </h3>
		The images used for training and test data were taken from the following websites:<br>
		<a href="http://www.freefoto.com/index.jsp">Real Photographs</a><br>
		<a href="http://www.raph.com/3dartists/">Photorealistic Drawings</a><br>
		<a href="https://openclipart.org/">Clip Art</a><br>
		<a href="http://3dmodelfree.com">Photorealistic 3D models</a><br>
		</p>
		<p>
		</p><h3> References </h3>
		<a href="http://www.ists.dartmouth.edu/library/31.pdf">How Realistic is Photorealistic? (Lyu & Farid, 2005)</a><br>
		<a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf">ImageNet Classification with Deep Convolutional Neural Networks (Krizhevsky et. al, 2012)</a><br>		
		<a href="http://caffe.berkeleyvision.org/">Caffe deep learning framework</a><br>
		<a href="http://scikit-learn.org/stable/">Python machine learning framework</a><br>
		<p></p>
		<p>
		</p><h3> Source Code </h3>
		<a href="https://github.com/jingdao/Computational-Photography">https://github.com/jingdao/Computational-Photography</a>
		<p></p>
	</div>


</body></html>
